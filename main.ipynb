{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Лабораторна робота № 6\n",
    "Смислов Даніл\n",
    "ІП-01\n",
    "\n",
    "Спочатку імпортуємо потрібні для роботи бібліотеки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Далі імпортуємо дані з файлу titanic.csv з кодуванням 'cp1252' та розділювачем ','. Розглянемо структуру датафрейму."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getDataset():\n",
    "    data = pd.read_csv('titanic.csv',sep=',',encoding='cp1252',decimal='.')\n",
    "    return data \n",
    "\n",
    "dataset = getDataset()\n",
    "dataset.info()\n",
    "dataset.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Давайте змінимо тип стовпчику 'Pclass'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['Pclass'] = dataset['Pclass'].astype(str)\n",
    "dataset.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Тепер давайте видалимо стовпчики, які нам не будуть потрібні для побудови моделі."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.drop(columns=['PassengerId','Name','Ticket'])\n",
    "\n",
    "dataset.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Давайте перевіримо дані на пропуски."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.patches as mpatches\n",
    "import seaborn as sbrn\n",
    "plt.figure(figsize =(12,12))\n",
    "plt.title('Heat map of missing data')\n",
    "lst = []\n",
    "is_patch =mpatches.Patch(color = 'black', label = 'Data')\n",
    "non_patch =mpatches.Patch(color = 'white', label = 'Missing data')\n",
    "lst.append(is_patch)\n",
    "lst.append(non_patch)\n",
    "plt.legend(handles = lst,bbox_to_anchor = (1,1))\n",
    "sbrn.heatmap(dataset.isna(),cmap = sbrn.color_palette(['Black','White']))\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Тепер давайте ще подивимось на к-сть пропущених даних."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "number = dataset.isnull().sum().sort_values(ascending=False)\n",
    "percent = (number / (dataset.count()+dataset.isnull().sum())*100).sort_values(ascending=False)\n",
    "missingData = pd.concat([number,percent],axis=1,keys = ['Number NaN','Percent NaN'])\n",
    "missingData.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Як ми бачимо, стовпець 'Cabin' має досить багато пропущених значень, тому давайте видалимо його. В стовцях 'Age' та 'Embarked' замінимо пропущені значення моди."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.drop(columns = 'Cabin')\n",
    "dataset['Embarked'] = dataset['Embarked'].fillna(dataset['Embarked'].mode()[0])\n",
    "dataset['Age'] = dataset['Age'].fillna(dataset['Age'].mode()[0])\n",
    "number = dataset.isnull().sum().sort_values(ascending=False)\n",
    "percent = (number / (dataset.count()+dataset.isnull().sum())*100).sort_values(ascending=False)\n",
    "missingData = pd.concat([number,percent],axis=1,keys = ['Number NaN','Percent NaN'])\n",
    "missingData.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Як ми бачимо, тепер всі дані заповненні, тож ми готові працювати з даними. Тепер давайте розподілимо дані на тренувальні та дані для тесту."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "trainingData, testingData  = train_test_split(dataset,test_size=0.2,random_state = 1)\n",
    "features = pd.concat([trainingData,testingData]).reset_index(drop = True)\n",
    "features = pd.get_dummies(features)\n",
    "trainingData = features.iloc[:trainingData.shape[0],:]\n",
    "testingData = features.iloc[trainingData.shape[0]:,:]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Тепер визначимо змінні X та Y для тренувальних та тестувальних даних."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainingX  = trainingData.drop(columns='Survived')\n",
    "trainingY = trainingData['Survived']\n",
    "\n",
    "testingX  = testingData.drop(columns='Survived')\n",
    "testingY = testingData['Survived']\n",
    "\n",
    "print(trainingY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Додамо необхідні бібліотеки для побудови моделей, побудуємо їх та перевіримо на тестових даних. Спочатку класифікатор Decision Tree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "decisionTree = DecisionTreeClassifier(max_depth=3,random_state=1)\n",
    "tree_scores = cross_val_score(decisionTree,trainingX,trainingY,cv = 5)\n",
    "print('Cvs in Decision Tree:', tree_scores.mean())\n",
    "decisionTree.fit(trainingX,trainingY)\n",
    "print('Score of Decision Tree:',decisionTree.score(testingX,testingY)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Тепер класифікатор Random Forest. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "randomForest = RandomForestClassifier(max_depth=5)\n",
    "tree_scores = cross_val_score(randomForest,trainingX,trainingY,cv = 5)\n",
    "print('Cvs in Random Forest:', tree_scores.mean())\n",
    "randomForest.fit(trainingX,trainingY)\n",
    "print('Score of Random Forest:',randomForest.score(testingX,testingY)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Тепер класифікатор Gradient Boosting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gradientBoosting = GradientBoostingClassifier(learning_rate = 0.1)\n",
    "tree_scores = cross_val_score(gradientBoosting,trainingX,trainingY,cv = 5)\n",
    "print('Cvs in Gradient Boosting:', tree_scores.mean())\n",
    "gradientBoosting.fit(trainingX,trainingY)\n",
    "GradientBoostingClassifier(learning_rate = 0.1)\n",
    "print('Score of Gradient Boosting:',gradientBoosting.score(testingX,testingY)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Тепер класифікатор AdaBoost."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adaBoosting = AdaBoostClassifier(learning_rate = 0.3)\n",
    "tree_scores = cross_val_score(adaBoosting,trainingX,trainingY,cv = 5)\n",
    "print('Cvs in Ada Boosting:', tree_scores.mean())\n",
    "adaBoosting.fit(trainingX,trainingY)\n",
    "print('Score of Ada Boosting:',adaBoosting.score(testingX,testingY)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Як ми бачимо, на тестових даних найкраще себе показав класифікатор Decision Tree, адже в нього найвище значення score. Але можна сказати, що моделі в цілому показали досить схожий результат."
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "cd33f47137b00f9a3c223ad7cd7ea8009173bfffa8c9627ff61bae578e5b56e2"
  },
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
